
Part I Basics.- Six Sigma in a Nutshell.- R from the Beginning.
Part II R Tools for the Define phase.- Process Mapping with R.- Loss Function Analysis with R.
Part III R Tools for the Measure phase.- Measurement System Analysis with R.- Pareto Analysis with R.- Process Capability Analysis with R.
Part IV R Tools for the Analyze phase.- Charts with R.- Statistics and Probability with R.- Statistical Inference with R.
Part V R Tools for the Improve phase.- Design of Experiments with R.
Part VI R Tools for the Control phase.- Process Control with R.
Part VII Further and Beyond.- Other Tools and Methodologies.
D phase
M phase
%============================================================================================================ %
Pareto analysis is a statistical technique in decision making that is used for selection of a limited number of tasks that
produce significant overall effect. It uses the Pareto principle – the idea that by doing 20\% of work, 80\% of the advantage
of doing the entire job can be generated.  Or in terms of quality improvement, a large majority of problems (80\%) are produced by a few key causes (20\%).
 
%============================================================================================================ %
Pareto analysis is a formal technique useful where many possible courses of action are competing for attention.
In essence, the problem-solver estimates the benefit delivered by each action, then selects a number of the most
effective actions that deliver a total benefit reasonably close to the maximal possible one.
C phase

%============================================================================================================ %
Statistical process control (SPC) is a method of quality control which uses statistical methods. SPC is applied in order to monitor and control a process. Monitoring and controlling the process ensures that it operates at its full potential. At its full potential, the process can make as much conforming product as possible with a minimum (if not an elimination) of waste (rework or trash). SPC can be applied to any process where the "conforming product" (product meeting specifications) output can be measured. Some key tools are used in SPC. These include control charts; a focus on continuous improvement; and the design of experiments.
An example of a process where SPC is applied is manufacturing lines.


%============================================================================================================ %
Pareto Charts
Improved QC Charts
QC: Quality Control
SixSigma R package
Process Capability Index

Taguchi methods are statistical methods developed by Genichi Taguchi to improve the quality of manufactured goods, and more recently also applied to engineering,[1] biotechnology,[2][3] marketing and advertising.[4] Professional statisticians have welcomed the goals and improvements brought about by Taguchi methods, particularly by Taguchi's development of designs for studying variation, but have criticized the inefficiency of some of Taguchi's proposals.[5]
%============================================================================================================ %
Taguchi's work includes three principal contributions to statistics:
 A specific loss function — see Taguchi loss function;
 The philosophy of off-line quality control; and
 Innovations in the design of experiments.
%============================================================================================================ %
In process improvement efforts, the process capability index or process capability ratio is a statistical measure of process capability: The ability of a process to produce output within specification limits.[1] The concept of process capability only holds meaning for processes that are in a state of statistical control. Process capability indices measure how much "natural variation" a process experiences relative to its specification limits and allows different processes to be compared with respect to how well an organization controls them.
%============================================================================================================ %
Tolerance analysis is the general term for activities related to the study of accumulated variation in mechanical parts and assemblies. Its methods may be used on other types of systems subject to accumulated variation, such as mechanical and electrical systems. Engineers analyze tolerances for the purpose of evaluating geometric dimensioning and tolerancing (GD&T). Methods include 2D tolerance stacks, 3D Monte Carlo simulations, and datum conversions.
 
Tolerance stackups or tolerance stacks are terms used to describe the problem-solving process in mechanical engineering of calculating the effects of the accumulated variation that is allowed by specified dimensions and tolerances. Typically these dimensions and tolerances are specified on an engineering drawing. Arithmetic tolerance stackups use the worst-case maximum or minimum values of dimensions and tolerances to calculate the maximum and minimum distance (clearance or interference) between two features or parts. Statistical tolerance stackups evaluate the maximum and minimum values based on the absolute arithmetic calculation combined with some method for establishing likelihood of obtaining the maximum and minimum values, such as Root Sum Square (RSS) or Monte-Carlo methods.
%============================================================================================================ % 
In performing a tolerance analysis, there are two fundamentally different analysis tools for predicting stackup variation: worst-case analysis and statistical analysis. Worst-case tolerance analysis is the traditional type of tolerance stackup calculation. The individual variables are placed at their tolerance limits in order to make the measurement as large or as small as possible. The worst-case model does not consider the distribution of the individual variables, but rather that those variables do not exceed their respective specified limits. This model predicts the maximum expected variation of the measurement.Designing to worst-case tolerance requirements guarantees 100 percent of the parts will assemble and function properly, regardless of the actual component variation. The major drawback is that the worst-case model often requires very tight individual component tolerances. 
%============================================================================================================ %
The obvious result is expensive manufacturing and inspection processes and/or high scrap rates. Worst-case tolerancing is often required by the customer for critical mechanical interfaces and spare part replacement interfaces. When worst-case tolerancing is not a contract requirement, properly applied statistical tolerancing can ensure acceptable assembly yields with increased component tolerances and lower fabrication costs. 
%============================================================================================================ %
The statistical variation analysis model takes advantage of the principles of statistics to relax the component tolerances without sacrificing quality. Each component’s variation is modeled as a statistical distribution and these distributions are summed to predict the distribution of the assembly measurement. Thus, statistical variation analysis predicts a distribution that describes the assembly variation, not the extreme values of that variation. This analysis model provides increased design flexibility by allowing the designer to design to any quality level, not just 100 percent.
%============================================================================================================ %
While no official engineering standard covers the process or format of tolerance analysis and stackups, these are essential components of good product design. Tolerance stackups should be used as part of the mechanical design process, both as a predictive and a problem-solving tool. The methods used to conduct a tolerance stackup depend somewhat upon the engineering dimensioning and tolerancing standards that are referenced in the engineering documentation, such as American Society of Mechanical Engineers (ASME) Y14.5, ASME Y14.41, or the relevant ISO dimensioning and tolerancing standards. Understanding the tolerances, concepts and boundaries created by these standards is vital to performing accurate calculations.
%============================================================================================================ % 
Tolerance stackups serve engineers by:
 helping them study dimensional relationships within an assembly.
 giving designers a means of calculating part tolerances.
 helping engineers compare design proposals.
 helping designers produce complete drawings.
%============================================================================================================ %